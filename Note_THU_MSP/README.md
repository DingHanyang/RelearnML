# B站马少平老师《跟我学AI》

目的是为了快速过一遍概念，很多东西忘记了。

## 激活函数

- Sigmoid （0,1）

- 符号函数 

- 双曲正切函数  区间是（-1,1）

- 线性整流函数 ReLU函数  ReLU(net) = max(0,net)

- Sotfmax函数 

  ![image-20231125235639781](F:\XJTLU\RelearnML\Note_THU_MSP\README.assets\image-20231125235639781.png)

  ## 全连接网络

  - 全连接网络
  - 前馈网络
  - 多层感知机（MLP）
  - 全连接层
  - 稠密层

  ## 损失函数
  
  ![image-20231127223116576](F:\XJTLU\RelearnML\Note_THU_MSP\README.assets\image-20231127223116576.png)
  note:1/2 是为了后续求导
  
  ## 梯度下降
  
  ![image-20231127223359462](F:\XJTLU\RelearnML\Note_THU_MSP\README.assets\image-20231127223359462.png)
  修改值太大可能会产生震荡
  
  ![image-20231127224144119](F:\XJTLU\RelearnML\Note_THU_MSP\README.assets\image-20231127224144119.png)
  
  ![image-20231127224543392](F:\XJTLU\RelearnML\Note_THU_MSP\README.assets\image-20231127224543392.png)
  
  ## 反向传播算法（BP: Back propagation）
  
  

​	
